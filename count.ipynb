{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6702f602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.solutions import object_counter\n",
    "import cv2\n",
    "\n",
    "# Initialize YOLO model\n",
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "\n",
    "# Set up your video source\n",
    "cap = cv2.VideoCapture(0)\n",
    "classes_to_count = [0, 2,18] \n",
    "# Initialize Object Counter for your line\n",
    "line_pedestrian_1 =  [(100, 100), (600, 100), (600, 360), (100, 360)]  # Define as per your need\n",
    "counter = object_counter.ObjectCounter()\n",
    "counter.set_args(view_img=True, reg_pts=line_pedestrian_1, classes_names=model.names)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, im0 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Track objects\n",
    "    results = model.track(im0,persist=True, show=False, classes=classes_to_count)\n",
    "\n",
    "    # Start counting based on tracks and your line\n",
    "    im0 = counter.start_counting(im0, results)\n",
    "\n",
    "    # Display\n",
    "    cv2.imshow(\"Count\", im0)\n",
    "    if cv2.waitKey(1) == ord('q'):  # press q to quit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad789d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d1526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.solutions import object_counter\n",
    "import cv2\n",
    "\n",
    "# Initialize YOLO model\n",
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "\n",
    "# Set up your video source\n",
    "cap = cv2.VideoCapture(0)\n",
    "classes_to_count = [0, 2,18] \n",
    "# Initialize Object Counter for your line\n",
    "line_pedestrian_1 =  [(100, 100), (600, 100), (600, 360), (100, 360)]  # Define as per your need\n",
    "counter = object_counter.ObjectCounter()\n",
    "\n",
    "#counter.set_args(view_img=True, reg_pts=line_pedestrian_1, classes_names=model.names)\n",
    "unique_ids = set()\n",
    "while cap.isOpened():\n",
    "    ret, im0 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Track objects\n",
    "    results = model.track(im0,persist=True, show=False, classes=classes_to_count)\n",
    "\n",
    "    \n",
    "    unique_ids.update([track.id for track in results.boxes])\n",
    "    \n",
    "    \n",
    "    # Start counting based on tracks and your line\n",
    "    im0 = counter.start_counting(im0, results)\n",
    "    \n",
    "    # Display\n",
    "    cv2.imshow(\"Count\", im0)\n",
    "    if cv2.waitKey(1) == ord('q'):  # press q to quit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "people_count = len(unique_ids)\n",
    "print(f\"Total unique people counted: {people_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b48d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from ultralytics.solutions import object_counter\n",
    "import cv2\n",
    "\n",
    "# Load your model\n",
    "model = YOLO(\"best.pt\")\n",
    "cap = cv2.VideoCapture(\"videoplayback.mp4\")\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "counter = object_counter.ObjectCounter()\n",
    "reg_pts = [(0, 0), (frame_width, 0), (frame_width, frame_height), (0, frame_height)]\n",
    "counter.set_args(view_img=True, classes_names=model.names, draw_tracks=False, reg_pts=reg_pts)\n",
    "classes_to_count = [0, 2, 18]\n",
    "class_counts = {0: 0, 16: 0, 15: 0}\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "        break  # End of video\n",
    "    tracks = model.track(im0, persist=True, show=False)\n",
    "    \n",
    "    # Update counts\n",
    "    for track in tracks:\n",
    "        cls_id = track.cls  # This is how you get class ID\n",
    "        if cls_id in class_counts:\n",
    "            class_counts[cls_id] += 1  # Increment count\n",
    "\n",
    "# After the loop, print your counts\n",
    "print(f\"Person count: {class_counts[0]}, Cat count: {class_counts[15]}, Dog count: {class_counts[16]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857b5550",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Initialize your model\n",
    "model = YOLO(\"best.pt\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Assuming cap is your cv2.VideoCapture object for your video stream\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break \n",
    "    \n",
    "    # Perform object tracking\n",
    "    results = model.track(frame, persist=True)\n",
    "\n",
    "    if isinstance(results, list):\n",
    "        print(\"Object tracking might not be enabled. Check Ultralytics documentation for requirements.\")\n",
    "        continue  # Skip to next iteration if results is a list\n",
    "\n",
    "    for track in results.tracks:  # Access tracks if available\n",
    "        class_id = track.class_id\n",
    "        class_name = model.names[class_id]\n",
    "        print(class_name)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):  # Press 'q' to quit the video frame\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa6e311",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "obj_name={}\n",
    "def test_yolo(image_path):\n",
    "    model = YOLO(\"best.pt\")\n",
    "    results = model(image_path)\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = test_yolo('/content/ddrive/MyDrive/Project/WhatsApp Image 2024-02-29 at 6.38)\n",
    "    count = 0\n",
    "    results_array = json.loads(results[0].tojson())\n",
    "\n",
    "\n",
    "\n",
    "    object_counts = defaultdict(int)\n",
    "\n",
    "    # Count occurrences of each object name\n",
    "    for result in results_array:\n",
    "        if result:\n",
    "            object_counts[result['name']] += 1\n",
    "\n",
    "\n",
    "print(object_counts.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ae1b3cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 576x640 (no detections), 314.1ms\n",
      "Speed: 12.4ms preprocess, 314.1ms inference, 1489.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 255.3ms\n",
      "Speed: 0.0ms preprocess, 255.3ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 269.7ms\n",
      "Speed: 1.6ms preprocess, 269.7ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 268.2ms\n",
      "Speed: 0.0ms preprocess, 268.2ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 274.7ms\n",
      "Speed: 0.0ms preprocess, 274.7ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 268.7ms\n",
      "Speed: 4.2ms preprocess, 268.7ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 269.5ms\n",
      "Speed: 0.0ms preprocess, 269.5ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 267.3ms\n",
      "Speed: 0.0ms preprocess, 267.3ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 265.3ms\n",
      "Speed: 0.0ms preprocess, 265.3ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 271.5ms\n",
      "Speed: 2.6ms preprocess, 271.5ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 305.7ms\n",
      "Speed: 0.0ms preprocess, 305.7ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 271.0ms\n",
      "Speed: 3.0ms preprocess, 271.0ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 295.2ms\n",
      "Speed: 3.3ms preprocess, 295.2ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 291.3ms\n",
      "Speed: 6.5ms preprocess, 291.3ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 298.0ms\n",
      "Speed: 0.0ms preprocess, 298.0ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 301.4ms\n",
      "Speed: 0.0ms preprocess, 301.4ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 300.1ms\n",
      "Speed: 4.8ms preprocess, 300.1ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 241.4ms\n",
      "Speed: 2.5ms preprocess, 241.4ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 221.9ms\n",
      "Speed: 0.0ms preprocess, 221.9ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 240.2ms\n",
      "Speed: 3.8ms preprocess, 240.2ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 206.0ms\n",
      "Speed: 0.0ms preprocess, 206.0ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 227.7ms\n",
      "Speed: 2.9ms preprocess, 227.7ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 237.0ms\n",
      "Speed: 2.8ms preprocess, 237.0ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 211.9ms\n",
      "Speed: 0.0ms preprocess, 211.9ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 281.6ms\n",
      "Speed: 3.0ms preprocess, 281.6ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 248.9ms\n",
      "Speed: 4.0ms preprocess, 248.9ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 232.0ms\n",
      "Speed: 3.3ms preprocess, 232.0ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 233.5ms\n",
      "Speed: 3.1ms preprocess, 233.5ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 225.7ms\n",
      "Speed: 0.0ms preprocess, 225.7ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 204.2ms\n",
      "Speed: 2.5ms preprocess, 204.2ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 238.8ms\n",
      "Speed: 0.0ms preprocess, 238.8ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 219.5ms\n",
      "Speed: 4.4ms preprocess, 219.5ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 273.7ms\n",
      "Speed: 0.0ms preprocess, 273.7ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 279.1ms\n",
      "Speed: 5.6ms preprocess, 279.1ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 269.2ms\n",
      "Speed: 4.1ms preprocess, 269.2ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 278.6ms\n",
      "Speed: 0.0ms preprocess, 278.6ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 283.1ms\n",
      "Speed: 0.0ms preprocess, 283.1ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 294.7ms\n",
      "Speed: 0.0ms preprocess, 294.7ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 293.3ms\n",
      "Speed: 0.0ms preprocess, 293.3ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 297.7ms\n",
      "Speed: 0.0ms preprocess, 297.7ms inference, 0.7ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 283.1ms\n",
      "Speed: 0.0ms preprocess, 283.1ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 251.9ms\n",
      "Speed: 2.7ms preprocess, 251.9ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 264.2ms\n",
      "Speed: 3.8ms preprocess, 264.2ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 270.0ms\n",
      "Speed: 0.0ms preprocess, 270.0ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 264.4ms\n",
      "Speed: 3.2ms preprocess, 264.4ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 289.7ms\n",
      "Speed: 5.2ms preprocess, 289.7ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 298.5ms\n",
      "Speed: 3.0ms preprocess, 298.5ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 292.2ms\n",
      "Speed: 3.1ms preprocess, 292.2ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 271.5ms\n",
      "Speed: 4.4ms preprocess, 271.5ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 282.9ms\n",
      "Speed: 2.4ms preprocess, 282.9ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 280.4ms\n",
      "Speed: 2.3ms preprocess, 280.4ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 281.6ms\n",
      "Speed: 3.0ms preprocess, 281.6ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 282.1ms\n",
      "Speed: 0.0ms preprocess, 282.1ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 286.8ms\n",
      "Speed: 0.0ms preprocess, 286.8ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 280.1ms\n",
      "Speed: 2.6ms preprocess, 280.1ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 277.5ms\n",
      "Speed: 0.0ms preprocess, 277.5ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 270.5ms\n",
      "Speed: 4.5ms preprocess, 270.5ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 263.0ms\n",
      "Speed: 5.0ms preprocess, 263.0ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 2 Tropicana Smooth-Juices, 269.6ms\n",
      "Speed: 3.5ms preprocess, 269.6ms inference, 12.9ms postprocess per image at shape (1, 3, 576, 640)\n",
      "2\n",
      "['Tropicana Smooth-Juice']\n",
      "\n",
      "0: 576x640 (no detections), 277.0ms\n",
      "Speed: 3.6ms preprocess, 277.0ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 270.1ms\n",
      "Speed: 4.2ms preprocess, 270.1ms inference, 10.8ms postprocess per image at shape (1, 3, 576, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 576x640 (no detections), 274.4ms\n",
      "Speed: 1.9ms preprocess, 274.4ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 276.4ms\n",
      "Speed: 3.9ms preprocess, 276.4ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 1 Tropicana Smooth-Juice, 291.9ms\n",
      "Speed: 4.4ms preprocess, 291.9ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "1\n",
      "['Tropicana Smooth-Juice']\n",
      "\n",
      "0: 576x640 (no detections), 288.6ms\n",
      "Speed: 2.9ms preprocess, 288.6ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 290.6ms\n",
      "Speed: 3.2ms preprocess, 290.6ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 301.3ms\n",
      "Speed: 5.2ms preprocess, 301.3ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 272.6ms\n",
      "Speed: 0.0ms preprocess, 272.6ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 288.2ms\n",
      "Speed: 0.0ms preprocess, 288.2ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 278.6ms\n",
      "Speed: 5.4ms preprocess, 278.6ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 274.9ms\n",
      "Speed: 4.2ms preprocess, 274.9ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 284.5ms\n",
      "Speed: 4.0ms preprocess, 284.5ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 294.0ms\n",
      "Speed: 0.0ms preprocess, 294.0ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 284.5ms\n",
      "Speed: 0.0ms preprocess, 284.5ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 288.8ms\n",
      "Speed: 4.2ms preprocess, 288.8ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 303.2ms\n",
      "Speed: 7.6ms preprocess, 303.2ms inference, 0.8ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 309.8ms\n",
      "Speed: 0.0ms preprocess, 309.8ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 294.9ms\n",
      "Speed: 0.0ms preprocess, 294.9ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 284.4ms\n",
      "Speed: 6.4ms preprocess, 284.4ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 283.5ms\n",
      "Speed: 0.0ms preprocess, 283.5ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 292.2ms\n",
      "Speed: 0.0ms preprocess, 292.2ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 306.0ms\n",
      "Speed: 0.0ms preprocess, 306.0ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 300.1ms\n",
      "Speed: 0.0ms preprocess, 300.1ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 276.0ms\n",
      "Speed: 0.0ms preprocess, 276.0ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 271.5ms\n",
      "Speed: 4.1ms preprocess, 271.5ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 1 Tropicana Smooth-Juice, 285.9ms\n",
      "Speed: 0.0ms preprocess, 285.9ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "1\n",
      "['Tropicana Smooth-Juice']\n",
      "\n",
      "0: 576x640 (no detections), 299.0ms\n",
      "Speed: 3.8ms preprocess, 299.0ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 263.6ms\n",
      "Speed: 3.0ms preprocess, 263.6ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 279.1ms\n",
      "Speed: 5.5ms preprocess, 279.1ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 276.8ms\n",
      "Speed: 3.9ms preprocess, 276.8ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 275.5ms\n",
      "Speed: 3.5ms preprocess, 275.5ms inference, 1.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 288.1ms\n",
      "Speed: 3.1ms preprocess, 288.1ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 307.8ms\n",
      "Speed: 0.0ms preprocess, 307.8ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 293.7ms\n",
      "Speed: 4.3ms preprocess, 293.7ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 280.2ms\n",
      "Speed: 3.0ms preprocess, 280.2ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 287.4ms\n",
      "Speed: 4.2ms preprocess, 287.4ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 289.6ms\n",
      "Speed: 3.6ms preprocess, 289.6ms inference, 1.8ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 283.2ms\n",
      "Speed: 3.3ms preprocess, 283.2ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 297.5ms\n",
      "Speed: 4.3ms preprocess, 297.5ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 272.7ms\n",
      "Speed: 0.0ms preprocess, 272.7ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 274.8ms\n",
      "Speed: 4.2ms preprocess, 274.8ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 305.9ms\n",
      "Speed: 4.1ms preprocess, 305.9ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 307.2ms\n",
      "Speed: 4.7ms preprocess, 307.2ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 297.3ms\n",
      "Speed: 2.5ms preprocess, 297.3ms inference, 8.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 296.2ms\n",
      "Speed: 0.0ms preprocess, 296.2ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 293.0ms\n",
      "Speed: 3.0ms preprocess, 293.0ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 292.8ms\n",
      "Speed: 0.0ms preprocess, 292.8ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 293.4ms\n",
      "Speed: 0.0ms preprocess, 293.4ms inference, 13.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 292.1ms\n",
      "Speed: 5.6ms preprocess, 292.1ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 264.0ms\n",
      "Speed: 3.5ms preprocess, 264.0ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 282.2ms\n",
      "Speed: 0.0ms preprocess, 282.2ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 293.7ms\n",
      "Speed: 0.0ms preprocess, 293.7ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 301.9ms\n",
      "Speed: 6.2ms preprocess, 301.9ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 277.6ms\n",
      "Speed: 3.3ms preprocess, 277.6ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 282.6ms\n",
      "Speed: 2.2ms preprocess, 282.6ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 286.8ms\n",
      "Speed: 3.0ms preprocess, 286.8ms inference, 0.7ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 288.6ms\n",
      "Speed: 0.0ms preprocess, 288.6ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 283.8ms\n",
      "Speed: 5.8ms preprocess, 283.8ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 274.5ms\n",
      "Speed: 2.9ms preprocess, 274.5ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 275.5ms\n",
      "Speed: 0.0ms preprocess, 275.5ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 286.3ms\n",
      "Speed: 6.2ms preprocess, 286.3ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 268.1ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 3.2ms preprocess, 268.1ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 264.4ms\n",
      "Speed: 0.0ms preprocess, 264.4ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 288.2ms\n",
      "Speed: 2.1ms preprocess, 288.2ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 280.9ms\n",
      "Speed: 2.7ms preprocess, 280.9ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 267.5ms\n",
      "Speed: 0.0ms preprocess, 267.5ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 277.8ms\n",
      "Speed: 3.0ms preprocess, 277.8ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 263.0ms\n",
      "Speed: 0.0ms preprocess, 263.0ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 282.8ms\n",
      "Speed: 4.6ms preprocess, 282.8ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 290.3ms\n",
      "Speed: 4.0ms preprocess, 290.3ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 301.7ms\n",
      "Speed: 4.4ms preprocess, 301.7ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 291.6ms\n",
      "Speed: 0.0ms preprocess, 291.6ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 283.8ms\n",
      "Speed: 0.0ms preprocess, 283.8ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 274.0ms\n",
      "Speed: 0.5ms preprocess, 274.0ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 266.0ms\n",
      "Speed: 0.0ms preprocess, 266.0ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 309.9ms\n",
      "Speed: 0.0ms preprocess, 309.9ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 306.7ms\n",
      "Speed: 4.0ms preprocess, 306.7ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 295.9ms\n",
      "Speed: 3.2ms preprocess, 295.9ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 291.5ms\n",
      "Speed: 3.0ms preprocess, 291.5ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 298.9ms\n",
      "Speed: 2.2ms preprocess, 298.9ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 309.0ms\n",
      "Speed: 3.4ms preprocess, 309.0ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 295.6ms\n",
      "Speed: 1.9ms preprocess, 295.6ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 278.4ms\n",
      "Speed: 3.8ms preprocess, 278.4ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 286.8ms\n",
      "Speed: 0.0ms preprocess, 286.8ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 280.3ms\n",
      "Speed: 2.8ms preprocess, 280.3ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 278.9ms\n",
      "Speed: 3.2ms preprocess, 278.9ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 281.9ms\n",
      "Speed: 2.9ms preprocess, 281.9ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 288.3ms\n",
      "Speed: 3.6ms preprocess, 288.3ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 281.6ms\n",
      "Speed: 0.0ms preprocess, 281.6ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 275.4ms\n",
      "Speed: 4.0ms preprocess, 275.4ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 282.6ms\n",
      "Speed: 0.0ms preprocess, 282.6ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 280.2ms\n",
      "Speed: 4.5ms preprocess, 280.2ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 266.4ms\n",
      "Speed: 1.6ms preprocess, 266.4ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 266.6ms\n",
      "Speed: 5.4ms preprocess, 266.6ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 1 Tropicana Smooth-Juice, 277.8ms\n",
      "Speed: 0.0ms preprocess, 277.8ms inference, 16.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "1\n",
      "['Tropicana Smooth-Juice']\n",
      "\n",
      "0: 576x640 1 Tropicana Smooth-Juice, 287.1ms\n",
      "Speed: 0.5ms preprocess, 287.1ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "1\n",
      "['Tropicana Smooth-Juice']\n",
      "\n",
      "0: 576x640 (no detections), 248.4ms\n",
      "Speed: 0.0ms preprocess, 248.4ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 234.5ms\n",
      "Speed: 0.0ms preprocess, 234.5ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 186.2ms\n",
      "Speed: 2.4ms preprocess, 186.2ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 217.9ms\n",
      "Speed: 0.0ms preprocess, 217.9ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 (no detections), 202.0ms\n",
      "Speed: 0.0ms preprocess, 202.0ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "Tropicana Smooth-Juice\n",
      "24\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "\n",
    "x1 = 100\n",
    "y1 = 50\n",
    "x2 = 500\n",
    "y2 = 400\n",
    "model = YOLO(\"best.pt\")  # Load your YOLO model\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # Open the webcam\n",
    "a=0\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Capture a frame\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "    results = model(roi)  # Run object detection on the frame\n",
    "    results_array = json.loads(results[0].tojson())\n",
    "    #print(results_array)\n",
    "\n",
    "    object_counts = defaultdict(int)\n",
    "\n",
    "    for result in results_array:\n",
    "        if result:\n",
    "            object_counts[result['name']] += 1\n",
    "    \n",
    "\n",
    "    # Display object counts on the frame\n",
    "    for obj_name, count in object_counts.items():\n",
    "        cv2.putText(frame, f\"{obj_name}: {count}\", (10, 30 + 30 * len(object_counts)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Object Counting\", frame)  # Display the frame with counts\n",
    "    a=1\n",
    "    if object_counts:\n",
    "        i = object_counts\n",
    "        cou = list(i.values())[0]\n",
    "        item_name=list(i.keys())\n",
    "        count=i.values()\n",
    "        print(cou)\n",
    "        print(item_name)\n",
    "        if cou<3 and item_name[0]=='Pepsi Can':\n",
    "            break\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "#model = YOLO(\"best.pt\")\n",
    "p=0\n",
    "item_names=model.names\n",
    "for i in item_name:\n",
    "    for class_id, class_name in item_names.items():\n",
    "        if i==class_name:\n",
    "            p=class_id\n",
    "            print(class_name)\n",
    "            print(p)\n",
    "\n",
    "def working(p):\n",
    "    print(p)\n",
    "    if p==26:\n",
    "        print(\"hee\")\n",
    "        with open('value.txt', 'w') as file:\n",
    "            # Write new content to the file\n",
    "            file.write(\"200\")\n",
    "working(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c6ee890",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m i\u001b[38;5;241m=\u001b[39mobject_counts\n\u001b[1;32m----> 2\u001b[0m cou \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(cou)\n\u001b[0;32m      4\u001b[0m item_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(i\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "i=object_counts\n",
    "cou = list(i.values())[0]\n",
    "print(cou)\n",
    "item_name=list(i.keys())\n",
    "count=i.values()\n",
    "print(item_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7749d95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tropicana Smooth-Juice']\n"
     ]
    }
   ],
   "source": [
    "print(item_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4629220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6d467b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('value.txt', 'w') as file:\n",
    "    # Write new content to the file\n",
    "    file.write(\"20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14816223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9d34a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb1b2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Major_project",
   "language": "python",
   "name": "major_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
